{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>online_reason</th>\n",
       "      <th>algebra</th>\n",
       "      <th>geometry</th>\n",
       "      <th>russian</th>\n",
       "      <th>literature</th>\n",
       "      <th>history</th>\n",
       "      <th>foreign</th>\n",
       "      <th>physics</th>\n",
       "      <th>...</th>\n",
       "      <th>bio_other</th>\n",
       "      <th>geo_other</th>\n",
       "      <th>for_other</th>\n",
       "      <th>it_other</th>\n",
       "      <th>soc_other</th>\n",
       "      <th>his_other</th>\n",
       "      <th>no_other</th>\n",
       "      <th>vol_other</th>\n",
       "      <th>sport_other</th>\n",
       "      <th>events_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28.03.2018 0:16:56</td>\n",
       "      <td>Недостаточное качество или объем образовательн...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28.03.2018 0:27:16</td>\n",
       "      <td>Не люблю рано вставать</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28.03.2018 0:28:26</td>\n",
       "      <td>Хотел бы получить больше свободного времени</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28.03.2018 0:29:54</td>\n",
       "      <td>Не люблю рано вставать</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28.03.2018 0:30:29</td>\n",
       "      <td>Никогда не стал бы учиться онлайн</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                time  \\\n",
       "0           0  28.03.2018 0:16:56   \n",
       "1           1  28.03.2018 0:27:16   \n",
       "2           2  28.03.2018 0:28:26   \n",
       "3           3  28.03.2018 0:29:54   \n",
       "4           4  28.03.2018 0:30:29   \n",
       "\n",
       "                                       online_reason  algebra  geometry  \\\n",
       "0  Недостаточное качество или объем образовательн...      4.2       4.6   \n",
       "1                             Не люблю рано вставать      3.7       3.2   \n",
       "2        Хотел бы получить больше свободного времени      4.8       4.7   \n",
       "3                             Не люблю рано вставать      4.8       4.9   \n",
       "4                  Никогда не стал бы учиться онлайн      4.2       4.1   \n",
       "\n",
       "   russian  literature  history  foreign  physics      ...       bio_other  \\\n",
       "0      4.0         4.7      4.7      4.9      4.9      ...               0   \n",
       "1      4.7         4.8      4.5      4.9      3.3      ...               0   \n",
       "2      4.6         4.3      3.6      4.7      4.7      ...               0   \n",
       "3      4.9         5.0      4.8      4.9      4.7      ...               0   \n",
       "4      4.7         4.7      4.7      4.9      4.3      ...               0   \n",
       "\n",
       "   geo_other  for_other  it_other  soc_other his_other  no_other  vol_other  \\\n",
       "0          0          0         0          1         0         0          0   \n",
       "1          0          0         1          0         0         0          1   \n",
       "2          0          0         0          0         0         1          0   \n",
       "3          0          0         0          0         0         0          0   \n",
       "4          0          0         0          0         0         1          1   \n",
       "\n",
       "   sport_other  events_other  \n",
       "0            0             0  \n",
       "1            0             1  \n",
       "2            1             1  \n",
       "3            1             1  \n",
       "4            1             1  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#читаем созданный в предыдущей программе набор данных\n",
    "import pandas as pd\n",
    "grades_df = pd.read_csv('grades_df.csv')\n",
    "grades_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#задаем названия переменным\n",
    "import numpy as np\n",
    "adm_short = ['gum', 'it', 'econ', 'ped', 'med', 'est', 'ing']\n",
    "subj_short = ['alg', 'geom', 'rus', 'lit', 'phy', 'chem', 'bio', 'geo', 'for', 'it', 'soc', 'his', 'no']\n",
    "olymps_short = ['math', 'rus', 'lit', 'phy', 'chem', 'bio', 'geo', 'for', 'it', 'soc', 'his', 'no']\n",
    "subjects_eng = 'algebra\tgeometry\trussian\tliterature\thistory\tforeign\tphysics\tchemystry\tgeography\tsocial\tbiology\tinformatics'.split('\t')\n",
    "\n",
    "olymps_full = np.concatenate([[a+'_town', a+'_region', a+'_state', a+'_other'] for a in olymps_short])\n",
    "subj_base = [a+'_base' for a in subj_short]\n",
    "subj_adv = [a+'_adv' for a in subj_short]\n",
    "vol = ['vol_other', 'sport_other', 'events_other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a898c2ae2271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcurr_subj_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msubj\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubj_base\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msubj\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_labeles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0molymps_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_subj_base\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubj_adv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubjects_eng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     X_train, X_test, y_train, y_test = train_test_split(grades_df[X_labeles],\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                         grades_df[i], random_state = 42, test_size = 0.5)\n\u001b[1;32m      8\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "subj_base_log_predictions = []\n",
    "subj_base_log_real = []\n",
    "for i in subj_base:\n",
    "    curr_subj_base = [subj for subj in subj_base if subj!=i]\n",
    "    X_labeles = list(olymps_full)+list(curr_subj_base)+list(subj_adv)+list(subjects_eng)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(grades_df[X_labeles],\n",
    "                                                        grades_df[i], random_state = 42, test_size = 0.5)\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    svc_reg = LinearSVC()\n",
    "    svc_reg.fit(X_train, y_train)\n",
    "    multy = MultinomialNB()\n",
    "    multy.fit(X_train, y_train)\n",
    "    ber = BernoulliNB()\n",
    "    gauss = GaussianNB()\n",
    "    gauss.fit(X_train, y_train)\n",
    "    ber.fit(X_train, y_train)\n",
    "    knn = KNeighborsClassifier(9)\n",
    "    knn.fit(X_train, y_train)\n",
    "    dummy = DummyClassifier('most_frequent')\n",
    "    dummy.fit(X_train, y_train)\n",
    "    print(i+'\\nDummy score: {0}'.format(round(dummy.score(X_test, y_test),3)))\n",
    "    print('Dummy AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in dummy.predict_proba(X_test)])))\n",
    "    print('Logistic regression')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in log_reg.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(log_reg.score(X_train, y_train),3), round(log_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(log_reg.predict(X_test), y_test))\n",
    "    print('LinearSVC')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(svc_reg.score(X_train, y_train),3), round(svc_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(svc_reg.predict(X_test), y_test))\n",
    "    print('KNeighborsClassifier')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(knn.score(X_train, y_train),3), round(knn.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(knn.predict(X_test), y_test))\n",
    "    print('MultinomialNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in multy.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(multy.score(X_train, y_train),3), round(multy.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(multy.predict(X_test), y_test))\n",
    "    print('BernoulliNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in ber.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(ber.score(X_train, y_train),3), round(ber.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(ber.predict(X_test), y_test))\n",
    "    print('GaussianNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in gauss.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(gauss.score(X_train, y_train),3), \n",
    "                                                     round(gauss.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(gauss.predict(X_test), y_test))\n",
    "    print('\\n')\n",
    "    \n",
    "    subj_base_log_predictions.append([a[1] for a in log_reg.predict_proba(X_test)])\n",
    "    subj_base_log_real.append(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alg_base': 11, 'geom_base': 17, 'rus_base': 18, 'lit_base': 53, 'phy_base': 56, 'chem_base': 52, 'bio_base': 50, 'geo_base': 92, 'for_base': 32, 'it_base': 85, 'soc_base': 65, 'his_base': 65, 'no_base': 39}\n",
      "{'alg_base': 13, 'geom_base': 15, 'rus_base': 12, 'lit_base': 32, 'phy_base': 31, 'chem_base': 32, 'bio_base': 33, 'geo_base': 54, 'for_base': 16, 'it_base': 50, 'soc_base': 36, 'his_base': 39, 'no_base': 25}\n",
      "Top 5 score is 0.9291338582677166\n"
     ]
    }
   ],
   "source": [
    "import random as rnd\n",
    "predictions = [list(zip(predicts, subj_base)) for predicts in np.transpose(subj_base_log_predictions)]\n",
    "reals = [list(zip(real, subj_base)) for real in np.transpose(subj_base_log_real)]\n",
    "#print(sorted(real[111], reverse = True))\n",
    "pred_dist = {}\n",
    "real_dist = {}\n",
    "for subj in subj_base:\n",
    "    pred_dist[subj]=0\n",
    "    real_dist[subj]=0\n",
    "good = 0\n",
    "num = len(reals)\n",
    "top_num = 5\n",
    "for i in range(num):\n",
    "    pred = [preds[1] for preds in sorted(predictions[i], reverse = True)][0:top_num]\n",
    "    #pred = rnd.sample(subj_base, top_num)\n",
    "    real = [real[1] for real in sorted(reals[i], reverse = True) if real[0]==1]\n",
    "    \n",
    "    for z in real:\n",
    "        if z in pred:\n",
    "            good = good+1\n",
    "            break\n",
    "    for z in real:\n",
    "        real_dist[z]+=1\n",
    "    for z in pred:\n",
    "        pred_dist[z]+=1\n",
    "print(pred_dist)\n",
    "print(real_dist) \n",
    "    \n",
    "print('Top {0} score is {1}'.format(top_num, good/num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alg_adv\n",
      "Dummy score: 0.702\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7942641509433962\n",
      "Train score: 0.96\n",
      "Test score: 0.764\n",
      "[[116  33]\n",
      " [  9  20]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.747\n",
      "[[108  28]\n",
      " [ 17  25]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.773\n",
      "Test score: 0.708\n",
      "[[125  52]\n",
      " [  0   1]]\n",
      "MultinomialNB\n",
      "AUC score 0.8469433962264151\n",
      "Train score: 0.893\n",
      "Test score: 0.747\n",
      "[[117  37]\n",
      " [  8  16]]\n",
      "BernoulliNB\n",
      "AUC score 0.8561509433962264\n",
      "Train score: 0.893\n",
      "Test score: 0.742\n",
      "[[114  35]\n",
      " [ 11  18]]\n",
      "GaussianNB\n",
      "AUC score 0.6376603773584906\n",
      "Train score: 0.667\n",
      "Test score: 0.567\n",
      "[[58 10]\n",
      " [67 43]]\n",
      "\n",
      "\n",
      "geom_adv\n",
      "Dummy score: 0.815\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.786833855799373\n",
      "Train score: 0.973\n",
      "Test score: 0.82\n",
      "[[141  28]\n",
      " [  4   5]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.831\n",
      "[[137  22]\n",
      " [  8  11]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.84\n",
      "Test score: 0.815\n",
      "[[145  33]\n",
      " [  0   0]]\n",
      "MultinomialNB\n",
      "AUC score 0.8033437826541274\n",
      "Train score: 0.893\n",
      "Test score: 0.815\n",
      "[[142  30]\n",
      " [  3   3]]\n",
      "BernoulliNB\n",
      "AUC score 0.8380355276907001\n",
      "Train score: 0.92\n",
      "Test score: 0.826\n",
      "[[142  28]\n",
      " [  3   5]]\n",
      "GaussianNB\n",
      "AUC score 0.5954022988505746\n",
      "Train score: 0.72\n",
      "Test score: 0.551\n",
      "[[76 11]\n",
      " [69 22]]\n",
      "\n",
      "\n",
      "rus_adv\n",
      "Dummy score: 0.854\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7788461538461539\n",
      "Train score: 0.987\n",
      "Test score: 0.815\n",
      "[[137  18]\n",
      " [ 15   8]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.781\n",
      "[[128  15]\n",
      " [ 24  11]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.827\n",
      "Test score: 0.854\n",
      "[[152  26]\n",
      " [  0   0]]\n",
      "MultinomialNB\n",
      "AUC score 0.750759109311741\n",
      "Train score: 0.907\n",
      "Test score: 0.787\n",
      "[[134  20]\n",
      " [ 18   6]]\n",
      "BernoulliNB\n",
      "AUC score 0.757338056680162\n",
      "Train score: 0.92\n",
      "Test score: 0.781\n",
      "[[130  17]\n",
      " [ 22   9]]\n",
      "GaussianNB\n",
      "AUC score 0.6586538461538461\n",
      "Train score: 0.773\n",
      "Test score: 0.635\n",
      "[[95  8]\n",
      " [57 18]]\n",
      "\n",
      "\n",
      "lit_adv\n",
      "Dummy score: 0.798\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7055946791862284\n",
      "Train score: 0.96\n",
      "Test score: 0.747\n",
      "[[126  29]\n",
      " [ 16   7]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.674\n",
      "[[109  25]\n",
      " [ 33  11]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.8\n",
      "Test score: 0.781\n",
      "[[138  35]\n",
      " [  4   1]]\n",
      "MultinomialNB\n",
      "AUC score 0.7674100156494523\n",
      "Train score: 0.893\n",
      "Test score: 0.775\n",
      "[[125  23]\n",
      " [ 17  13]]\n",
      "BernoulliNB\n",
      "AUC score 0.7480438184663536\n",
      "Train score: 0.893\n",
      "Test score: 0.787\n",
      "[[125  21]\n",
      " [ 17  15]]\n",
      "GaussianNB\n",
      "AUC score 0.6226525821596245\n",
      "Train score: 0.907\n",
      "Test score: 0.646\n",
      "[[94 15]\n",
      " [48 21]]\n",
      "\n",
      "\n",
      "phy_adv\n",
      "Dummy score: 0.82\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7106164383561644\n",
      "Train score: 0.973\n",
      "Test score: 0.837\n",
      "[[146  29]\n",
      " [  0   3]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.798\n",
      "[[136  26]\n",
      " [ 10   6]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.867\n",
      "Test score: 0.82\n",
      "[[146  32]\n",
      " [  0   0]]\n",
      "MultinomialNB\n",
      "AUC score 0.728595890410959\n",
      "Train score: 0.893\n",
      "Test score: 0.831\n",
      "[[146  30]\n",
      " [  0   2]]\n",
      "BernoulliNB\n",
      "AUC score 0.751498287671233\n",
      "Train score: 0.867\n",
      "Test score: 0.843\n",
      "[[145  27]\n",
      " [  1   5]]\n",
      "GaussianNB\n",
      "AUC score 0.5622859589041096\n",
      "Train score: 0.773\n",
      "Test score: 0.702\n",
      "[[114  21]\n",
      " [ 32  11]]\n",
      "\n",
      "\n",
      "chem_adv\n",
      "Dummy score: 0.888\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7734177215189874\n",
      "Train score: 1.0\n",
      "Test score: 0.888\n",
      "[[158  20]\n",
      " [  0   0]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.882\n",
      "[[156  19]\n",
      " [  2   1]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.933\n",
      "Test score: 0.888\n",
      "[[158  20]\n",
      " [  0   0]]\n",
      "MultinomialNB\n",
      "AUC score 0.8113924050632911\n",
      "Train score: 0.947\n",
      "Test score: 0.893\n",
      "[[158  19]\n",
      " [  0   1]]\n",
      "BernoulliNB\n",
      "AUC score 0.8354430379746836\n",
      "Train score: 0.96\n",
      "Test score: 0.893\n",
      "[[158  19]\n",
      " [  0   1]]\n",
      "GaussianNB\n",
      "AUC score 0.525\n",
      "Train score: 1.0\n",
      "Test score: 0.893\n",
      "[[158  19]\n",
      " [  0   1]]\n",
      "\n",
      "\n",
      "bio_adv\n",
      "Dummy score: 0.91\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.65625\n",
      "Train score: 1.0\n",
      "Test score: 0.899\n",
      "[[159  15]\n",
      " [  3   1]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.86\n",
      "[[150  13]\n",
      " [ 12   3]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.88\n",
      "Test score: 0.899\n",
      "[[160  16]\n",
      " [  2   0]]\n",
      "MultinomialNB\n",
      "AUC score 0.7025462962962963\n",
      "Train score: 0.96\n",
      "Test score: 0.899\n",
      "[[157  13]\n",
      " [  5   3]]\n",
      "BernoulliNB\n",
      "AUC score 0.6795910493827161\n",
      "Train score: 0.96\n",
      "Test score: 0.888\n",
      "[[156  14]\n",
      " [  6   2]]\n",
      "GaussianNB\n",
      "AUC score 0.5601851851851852\n",
      "Train score: 0.88\n",
      "Test score: 0.815\n",
      "[[141  12]\n",
      " [ 21   4]]\n",
      "\n",
      "\n",
      "geo_adv\n",
      "Dummy score: 0.933\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.731425702811245\n",
      "Train score: 0.973\n",
      "Test score: 0.933\n",
      "[[166  12]\n",
      " [  0   0]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.888\n",
      "[[155   9]\n",
      " [ 11   3]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.92\n",
      "Test score: 0.933\n",
      "[[166  12]\n",
      " [  0   0]]\n",
      "MultinomialNB\n",
      "AUC score 0.6892570281124497\n",
      "Train score: 0.92\n",
      "Test score: 0.927\n",
      "[[165  12]\n",
      " [  1   0]]\n",
      "BernoulliNB\n",
      "AUC score 0.6932730923694779\n",
      "Train score: 0.933\n",
      "Test score: 0.927\n",
      "[[165  12]\n",
      " [  1   0]]\n",
      "GaussianNB\n",
      "AUC score 0.4819277108433735\n",
      "Train score: 0.987\n",
      "Test score: 0.899\n",
      "[[160  12]\n",
      " [  6   0]]\n",
      "\n",
      "\n",
      "for_adv\n",
      "Dummy score: 0.534\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7459733671528218\n",
      "Train score: 0.973\n",
      "Test score: 0.646\n",
      "[[62 30]\n",
      " [33 53]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.635\n",
      "[[59 29]\n",
      " [36 54]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.707\n",
      "Test score: 0.618\n",
      "[[89 62]\n",
      " [ 6 21]]\n",
      "MultinomialNB\n",
      "AUC score 0.7580215599239062\n",
      "Train score: 0.827\n",
      "Test score: 0.685\n",
      "[[70 31]\n",
      " [25 52]]\n",
      "BernoulliNB\n",
      "AUC score 0.7620798985415346\n",
      "Train score: 0.813\n",
      "Test score: 0.68\n",
      "[[67 29]\n",
      " [28 54]]\n",
      "GaussianNB\n",
      "AUC score 0.7135066582117946\n",
      "Train score: 0.8\n",
      "Test score: 0.618\n",
      "[[76 49]\n",
      " [19 34]]\n",
      "\n",
      "\n",
      "it_adv\n",
      "Dummy score: 0.781\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.5633646928610958\n",
      "Train score: 1.0\n",
      "Test score: 0.691\n",
      "[[115  31]\n",
      " [ 24   8]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.657\n",
      "[[110  32]\n",
      " [ 29   7]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.747\n",
      "Test score: 0.775\n",
      "[[137  38]\n",
      " [  2   1]]\n",
      "MultinomialNB\n",
      "AUC score 0.5886367828813872\n",
      "Train score: 0.88\n",
      "Test score: 0.713\n",
      "[[120  32]\n",
      " [ 19   7]]\n",
      "BernoulliNB\n",
      "AUC score 0.5928795425198302\n",
      "Train score: 0.907\n",
      "Test score: 0.725\n",
      "[[118  28]\n",
      " [ 21  11]]\n",
      "GaussianNB\n",
      "AUC score 0.5808891348459694\n",
      "Train score: 0.867\n",
      "Test score: 0.725\n",
      "[[127  37]\n",
      " [ 12   2]]\n",
      "\n",
      "\n",
      "soc_adv\n",
      "Dummy score: 0.787\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.6885338345864662\n",
      "Train score: 0.987\n",
      "Test score: 0.742\n",
      "[[123  29]\n",
      " [ 17   9]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.691\n",
      "[[107  22]\n",
      " [ 33  16]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.76\n",
      "Test score: 0.787\n",
      "[[138  36]\n",
      " [  2   2]]\n",
      "MultinomialNB\n",
      "AUC score 0.675375939849624\n",
      "Train score: 0.867\n",
      "Test score: 0.725\n",
      "[[118  27]\n",
      " [ 22  11]]\n",
      "BernoulliNB\n",
      "AUC score 0.6704887218045112\n",
      "Train score: 0.853\n",
      "Test score: 0.708\n",
      "[[117  29]\n",
      " [ 23   9]]\n",
      "GaussianNB\n",
      "AUC score 0.6614661654135339\n",
      "Train score: 0.787\n",
      "Test score: 0.573\n",
      "[[71  7]\n",
      " [69 31]]\n",
      "\n",
      "\n",
      "his_adv\n",
      "Dummy score: 0.826\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.6458196181698487\n",
      "Train score: 0.947\n",
      "Test score: 0.815\n",
      "[[144  30]\n",
      " [  3   1]]\n",
      "LinearSVC\n",
      "Train score: 0.987\n",
      "Test score: 0.803\n",
      "[[137  25]\n",
      " [ 10   6]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.84\n",
      "Test score: 0.826\n",
      "[[147  31]\n",
      " [  0   0]]\n",
      "MultinomialNB\n",
      "AUC score 0.6747860434496379\n",
      "Train score: 0.88\n",
      "Test score: 0.809\n",
      "[[143  30]\n",
      " [  4   1]]\n",
      "BernoulliNB\n",
      "AUC score 0.6754443712969058\n",
      "Train score: 0.88\n",
      "Test score: 0.815\n",
      "[[143  29]\n",
      " [  4   2]]\n",
      "GaussianNB\n",
      "AUC score 0.618499012508229\n",
      "Train score: 0.76\n",
      "Test score: 0.601\n",
      "[[87 11]\n",
      " [60 20]]\n",
      "\n",
      "\n",
      "no_adv\n",
      "Dummy score: 0.798\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.9051251956181534\n",
      "Train score: 1.0\n",
      "Test score: 0.854\n",
      "[[130  14]\n",
      " [ 12  22]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.871\n",
      "[[128   9]\n",
      " [ 14  27]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.8\n",
      "Test score: 0.624\n",
      "[[81  6]\n",
      " [61 30]]\n",
      "MultinomialNB\n",
      "AUC score 0.9538341158059468\n",
      "Train score: 0.947\n",
      "Test score: 0.893\n",
      "[[131   8]\n",
      " [ 11  28]]\n",
      "BernoulliNB\n",
      "AUC score 0.9426838810641629\n",
      "Train score: 0.92\n",
      "Test score: 0.888\n",
      "[[129   7]\n",
      " [ 13  29]]\n",
      "GaussianNB\n",
      "AUC score 0.8333333333333333\n",
      "Train score: 1.0\n",
      "Test score: 0.933\n",
      "[[142  12]\n",
      " [  0  24]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subj_adv_log_predictions = [] \n",
    "subj_adv_log_real = []\n",
    "\n",
    "for i in subj_adv:\n",
    "    curr_subj_adv = [subj for subj in subj_adv if subj!=i]\n",
    "    X_labeles = list(olymps_full)+list(curr_subj_adv)+list(subj_base)+list(subjects_eng)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(grades_df[X_labeles],\n",
    "                                                        grades_df[i], random_state = 42, test_size = 0.7)\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    svc_reg = LinearSVC()\n",
    "    svc_reg.fit(X_train, y_train)\n",
    "    multy = MultinomialNB()\n",
    "    multy.fit(X_train, y_train)\n",
    "    ber = BernoulliNB()\n",
    "    gauss = GaussianNB()\n",
    "    gauss.fit(X_train, y_train)\n",
    "    ber.fit(X_train, y_train)\n",
    "    knn = KNeighborsClassifier(9)\n",
    "    knn.fit(X_train, y_train)\n",
    "    dummy = DummyClassifier('most_frequent')\n",
    "    dummy.fit(X_train, y_train)\n",
    "    print(i+'\\nDummy score: {0}'.format(round(dummy.score(X_test, y_test),3)))\n",
    "    print('Dummy AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in dummy.predict_proba(X_test)])))\n",
    "    print('Logistic regression')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in log_reg.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(log_reg.score(X_train, y_train),3), round(log_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(log_reg.predict(X_test), y_test))\n",
    "    print('LinearSVC')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(svc_reg.score(X_train, y_train),3), round(svc_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(svc_reg.predict(X_test), y_test))\n",
    "    print('KNeighborsClassifier')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(knn.score(X_train, y_train),3), round(knn.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(knn.predict(X_test), y_test))\n",
    "    print('MultinomialNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in multy.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(multy.score(X_train, y_train),3), round(multy.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(multy.predict(X_test), y_test))\n",
    "    print('BernoulliNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in ber.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(ber.score(X_train, y_train),3), round(ber.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(ber.predict(X_test), y_test))\n",
    "    print('GaussianNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in gauss.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(gauss.score(X_train, y_train),3), \n",
    "                                                     round(gauss.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(gauss.predict(X_test), y_test))\n",
    "    print('\\n')\n",
    "    subj_adv_log_predictions.append([a[1] for a in log_reg.predict_proba(X_test)])\n",
    "    subj_adv_log_real.append(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alg_adv': 15, 'geom_adv': 3, 'rus_adv': 3, 'lit_adv': 8, 'phy_adv': 1, 'chem_adv': 0, 'bio_adv': 3, 'geo_adv': 0, 'for_adv': 65, 'it_adv': 25, 'soc_adv': 12, 'his_adv': 0, 'no_adv': 43}\n",
      "{'alg_adv': 53, 'geom_adv': 33, 'rus_adv': 26, 'lit_adv': 36, 'phy_adv': 32, 'chem_adv': 20, 'bio_adv': 16, 'geo_adv': 12, 'for_adv': 83, 'it_adv': 39, 'soc_adv': 38, 'his_adv': 31, 'no_adv': 36}\n",
      "Top 1 score is 0.5056179775280899\n"
     ]
    }
   ],
   "source": [
    "predictions = [list(zip(predicts, subj_adv)) for predicts in np.transpose(subj_adv_log_predictions)]\n",
    "reals = [list(zip(real, subj_adv)) for real in np.transpose(subj_adv_log_real)]\n",
    "#print(sorted(real[111], reverse = True))\n",
    "pred_dist = {}\n",
    "real_dist = {}\n",
    "for subj in subj_adv:\n",
    "    pred_dist[subj]=0\n",
    "    real_dist[subj]=0\n",
    "good = 0\n",
    "num = len(reals)\n",
    "all_real = 0\n",
    "top_num = 1\n",
    "for i in range(num):\n",
    "    pred = [preds[1] for preds in sorted(predictions[i], reverse = True)][0:top_num]\n",
    "    #pred = rnd.sample(subj_base, top_num)\n",
    "    real = [real[1] for real in sorted(reals[i], reverse = True) if real[0]==1]\n",
    "    all_real += len(real)\n",
    "    for z in real:\n",
    "        if z in pred:\n",
    "            good = good+1\n",
    "            break\n",
    "    for z in real:\n",
    "        real_dist[z]+=1\n",
    "    for z in pred:\n",
    "        pred_dist[z]+=1\n",
    "print(pred_dist)\n",
    "print(real_dist) \n",
    "print('Top {0} score is {1}'.format(top_num, good/num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gum\n",
      "Dummy score: 0.647\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.6654040404040404\n",
      "Train score: 0.881\n",
      "Test score: 0.627\n",
      "[[40 12]\n",
      " [26 24]]\n",
      "LinearSVC\n",
      "Train score: 0.901\n",
      "Test score: 0.627\n",
      "[[45 17]\n",
      " [21 19]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.762\n",
      "Test score: 0.676\n",
      "[[54 21]\n",
      " [12 15]]\n",
      "MultinomialNB\n",
      "AUC score 0.7028619528619529\n",
      "Train score: 0.748\n",
      "Test score: 0.696\n",
      "[[52 17]\n",
      " [14 19]]\n",
      "BernoulliNB\n",
      "AUC score 0.6992845117845118\n",
      "Train score: 0.755\n",
      "Test score: 0.696\n",
      "[[51 16]\n",
      " [15 20]]\n",
      "GaussianNB\n",
      "AUC score 0.5536616161616161\n",
      "Train score: 0.536\n",
      "Test score: 0.373\n",
      "[[ 6  4]\n",
      " [60 32]]\n",
      "Lasso\n",
      "0.104259391469\n",
      "\n",
      "\n",
      "it\n",
      "Dummy score: 0.892\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.6683316683316685\n",
      "Train score: 0.894\n",
      "Test score: 0.892\n",
      "[[88  8]\n",
      " [ 3  3]]\n",
      "LinearSVC\n",
      "Train score: 0.974\n",
      "Test score: 0.873\n",
      "[[86  8]\n",
      " [ 5  3]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.861\n",
      "Test score: 0.902\n",
      "[[91 10]\n",
      " [ 0  1]]\n",
      "MultinomialNB\n",
      "AUC score 0.7052947052947053\n",
      "Train score: 0.894\n",
      "Test score: 0.892\n",
      "[[89  9]\n",
      " [ 2  2]]\n",
      "BernoulliNB\n",
      "AUC score 0.6818181818181819\n",
      "Train score: 0.901\n",
      "Test score: 0.882\n",
      "[[88  9]\n",
      " [ 3  2]]\n",
      "GaussianNB\n",
      "AUC score 0.5824175824175823\n",
      "Train score: 0.318\n",
      "Test score: 0.255\n",
      "[[15  0]\n",
      " [76 11]]\n",
      "Lasso\n",
      "0.116632136895\n",
      "\n",
      "\n",
      "econ\n",
      "Dummy score: 0.657\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7309168443496802\n",
      "Train score: 0.815\n",
      "Test score: 0.716\n",
      "[[63 25]\n",
      " [ 4 10]]\n",
      "LinearSVC\n",
      "Train score: 0.894\n",
      "Test score: 0.676\n",
      "[[56 22]\n",
      " [11 13]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.795\n",
      "Test score: 0.667\n",
      "[[62 29]\n",
      " [ 5  6]]\n",
      "MultinomialNB\n",
      "AUC score 0.6554371002132197\n",
      "Train score: 0.808\n",
      "Test score: 0.716\n",
      "[[58 20]\n",
      " [ 9 15]]\n",
      "BernoulliNB\n",
      "AUC score 0.6388059701492539\n",
      "Train score: 0.781\n",
      "Test score: 0.716\n",
      "[[58 20]\n",
      " [ 9 15]]\n",
      "GaussianNB\n",
      "AUC score 0.5181236673773987\n",
      "Train score: 0.47\n",
      "Test score: 0.412\n",
      "[[12  5]\n",
      " [55 30]]\n",
      "Lasso\n",
      "0.109204256846\n",
      "\n",
      "\n",
      "ped\n",
      "Dummy score: 0.922\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.49734042553191493\n",
      "Train score: 0.94\n",
      "Test score: 0.922\n",
      "[[94  8]\n",
      " [ 0  0]]\n",
      "LinearSVC\n",
      "Train score: 0.98\n",
      "Test score: 0.912\n",
      "[[91  6]\n",
      " [ 3  2]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.934\n",
      "Test score: 0.922\n",
      "[[94  8]\n",
      " [ 0  0]]\n",
      "MultinomialNB\n",
      "AUC score 0.625\n",
      "Train score: 0.927\n",
      "Test score: 0.912\n",
      "[[93  8]\n",
      " [ 1  0]]\n",
      "BernoulliNB\n",
      "AUC score 0.5777925531914894\n",
      "Train score: 0.927\n",
      "Test score: 0.912\n",
      "[[93  8]\n",
      " [ 1  0]]\n",
      "GaussianNB\n",
      "AUC score 0.5611702127659575\n",
      "Train score: 0.417\n",
      "Test score: 0.402\n",
      "[[35  2]\n",
      " [59  6]]\n",
      "Lasso\n",
      "-0.0342106980119\n",
      "\n",
      "\n",
      "med\n",
      "Dummy score: 0.912\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.5997610513739546\n",
      "Train score: 0.927\n",
      "Test score: 0.912\n",
      "[[93  9]\n",
      " [ 0  0]]\n",
      "LinearSVC\n",
      "Train score: 0.967\n",
      "Test score: 0.892\n",
      "[[91  9]\n",
      " [ 2  0]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.927\n",
      "Test score: 0.912\n",
      "[[93  9]\n",
      " [ 0  0]]\n",
      "MultinomialNB\n",
      "AUC score 0.5746714456391876\n",
      "Train score: 0.934\n",
      "Test score: 0.902\n",
      "[[92  9]\n",
      " [ 1  0]]\n",
      "BernoulliNB\n",
      "AUC score 0.553763440860215\n",
      "Train score: 0.94\n",
      "Test score: 0.902\n",
      "[[92  9]\n",
      " [ 1  0]]\n",
      "GaussianNB\n",
      "AUC score 0.44802867383512546\n",
      "Train score: 0.536\n",
      "Test score: 0.451\n",
      "[[42  5]\n",
      " [51  4]]\n",
      "Lasso\n",
      "0.00297040499403\n",
      "\n",
      "\n",
      "est\n",
      "Dummy score: 0.961\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.9336734693877551\n",
      "Train score: 0.934\n",
      "Test score: 0.971\n",
      "[[98  3]\n",
      " [ 0  1]]\n",
      "LinearSVC\n",
      "Train score: 0.967\n",
      "Test score: 0.961\n",
      "[[96  2]\n",
      " [ 2  2]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.901\n",
      "Test score: 0.961\n",
      "[[98  4]\n",
      " [ 0  0]]\n",
      "MultinomialNB\n",
      "AUC score 0.9260204081632653\n",
      "Train score: 0.934\n",
      "Test score: 0.951\n",
      "[[96  3]\n",
      " [ 2  1]]\n",
      "BernoulliNB\n",
      "AUC score 0.8979591836734694\n",
      "Train score: 0.934\n",
      "Test score: 0.951\n",
      "[[96  3]\n",
      " [ 2  1]]\n",
      "GaussianNB\n",
      "AUC score 0.5306122448979592\n",
      "Train score: 0.616\n",
      "Test score: 0.559\n",
      "[[55  2]\n",
      " [43  2]]\n",
      "Lasso\n",
      "0.194416048827\n",
      "\n",
      "\n",
      "ing\n",
      "Dummy score: 0.863\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7353896103896104\n",
      "Train score: 0.901\n",
      "Test score: 0.814\n",
      "[[82 13]\n",
      " [ 6  1]]\n",
      "LinearSVC\n",
      "Train score: 0.947\n",
      "Test score: 0.735\n",
      "[[69  8]\n",
      " [19  6]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.834\n",
      "Test score: 0.882\n",
      "[[88 12]\n",
      " [ 0  2]]\n",
      "MultinomialNB\n",
      "AUC score 0.8555194805194805\n",
      "Train score: 0.834\n",
      "Test score: 0.833\n",
      "[[84 13]\n",
      " [ 4  1]]\n",
      "BernoulliNB\n",
      "AUC score 0.84375\n",
      "Train score: 0.848\n",
      "Test score: 0.843\n",
      "[[85 13]\n",
      " [ 3  1]]\n",
      "GaussianNB\n",
      "AUC score 0.5381493506493507\n",
      "Train score: 0.364\n",
      "Test score: 0.255\n",
      "[[13  1]\n",
      " [75 13]]\n",
      "Lasso\n",
      "-0.018066719139\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#загружаем необходимые для анализа данных пакеты из библиотеки sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#создаем массивы для хранения предсказаний по каждой модели\n",
    "#и реальных значений переменных\n",
    "subj_log_predictions = [] \n",
    "subj_log_real = []\n",
    "subjs = subj_adv+subj_base\n",
    "lasso_save = []\n",
    "\n",
    "#цикл, который создает модель для каждого предмета\n",
    "#базовый и продвинутый предмет считаются за два\n",
    "for i in adm_short:\n",
    "    #разбиение массива данных на тренировочную и тестовую части\n",
    "    #тестовая часть составляет 40% от всего набора данных\n",
    "    curr_subj = [subj for subj in subjs if subj!=i]\n",
    "    X_labeles = list(olymps_full)+list(subjects_eng)+list(vol)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(grades_df[X_labeles],\n",
    "                                                        grades_df[i], random_state = 42, test_size = 0.4)\n",
    "    #создание моделей методами: логистической регрессии\n",
    "    #SVM, тремя видами Naive Bayes, kNearestNeighbours -\n",
    "    #и случайного классификатора\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    svc_reg = LinearSVC()\n",
    "    svc_reg.fit(X_train, y_train)\n",
    "    multy = MultinomialNB()\n",
    "    multy.fit(X_train, y_train)\n",
    "    ber = BernoulliNB()\n",
    "    gauss = GaussianNB()\n",
    "    gauss.fit(X_train, y_train)\n",
    "    ber.fit(X_train, y_train)\n",
    "    knn = KNeighborsClassifier(9)\n",
    "    knn.fit(X_train, y_train)\n",
    "    dummy = DummyClassifier('most_frequent')\n",
    "    dummy.fit(X_train, y_train)\n",
    "    #Вывод показателей по каждой модели\n",
    "    print(i+'\\nDummy score: {0}'.format(round(dummy.score(X_test, y_test),3)))\n",
    "    print('Dummy AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in dummy.predict_proba(X_test)])))\n",
    "    print('Logistic regression')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in log_reg.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(log_reg.score(X_train, y_train),3), round(log_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(log_reg.predict(X_test), y_test))\n",
    "    print('LinearSVC')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(svc_reg.score(X_train, y_train),3), round(svc_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(svc_reg.predict(X_test), y_test))\n",
    "    print('KNeighborsClassifier')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(knn.score(X_train, y_train),3), round(knn.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(knn.predict(X_test), y_test))\n",
    "    print('MultinomialNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in multy.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(multy.score(X_train, y_train),3), round(multy.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(multy.predict(X_test), y_test))\n",
    "    print('BernoulliNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in ber.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(ber.score(X_train, y_train),3), round(ber.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(ber.predict(X_test), y_test))\n",
    "    print('GaussianNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in gauss.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(gauss.score(X_train, y_train),3), \n",
    "                                                     round(gauss.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(gauss.predict(X_test), y_test))\n",
    "    print('Lasso')\n",
    "    Lss = Lasso(0.01)\n",
    "    Lss.fit(X_train, y_train)\n",
    "    print(Lss.score(X_test, y_test))\n",
    "    #Сохраняем данные по Лассо-модели для оценки\n",
    "    #значимсти переменных\n",
    "    lasso_save.append([x for x in zip(X_train.columns.values.tolist(), Lss.coef_)])\n",
    "    print('\\n')\n",
    "    subj_log_predictions.append([a[1] for a in ber.predict_proba(X_test)])\n",
    "    subj_log_real.append(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('for_adv', 11), ('alg_adv', 8), ('geo_base', 7), ('his_base', 7), ('no_base', 7), ('no_adv', 6), ('geom_base', 6), ('it_base', 6), ('chem_base', 4), ('soc_adv', 3), ('his_adv', 3), ('geom_adv', 2), ('bio_base', 2), ('lit_adv', 1), ('it_adv', 1), ('phy_base', 1), ('soc_base', 1), ('rus_adv', 0), ('phy_adv', 0), ('chem_adv', 0), ('bio_adv', 0), ('geo_adv', 0), ('alg_base', 0), ('rus_base', 0), ('lit_base', 0), ('for_base', 0)]\n",
      "[('for_adv', 37), ('geo_base', 32), ('it_base', 31), ('alg_adv', 22), ('soc_base', 22), ('his_base', 22), ('phy_base', 20), ('chem_base', 20), ('bio_base', 20), ('it_adv', 18), ('soc_adv', 17), ('no_adv', 17), ('lit_base', 17), ('geom_adv', 15), ('lit_adv', 15), ('phy_adv', 14), ('no_base', 14), ('rus_adv', 13), ('his_adv', 12), ('for_base', 10), ('chem_adv', 9), ('geo_adv', 8), ('geom_base', 8), ('rus_base', 8), ('alg_base', 7), ('bio_adv', 5)]\n",
      "Top 1 score is 0.7368421052631579\n",
      "Mean real num is 5.697368421052632\n",
      "Mean good num is 0.7368421052631579\n",
      "[('for_adv', 20), ('no_adv', 16), ('geo_base', 15), ('alg_adv', 14), ('his_base', 14), ('it_base', 13), ('no_base', 11), ('chem_base', 7), ('it_adv', 6), ('soc_adv', 6), ('geom_base', 6), ('bio_base', 5), ('his_adv', 4), ('geom_adv', 3), ('phy_base', 3), ('lit_adv', 2), ('lit_base', 2), ('soc_base', 2), ('phy_adv', 1), ('alg_base', 1), ('rus_base', 1), ('rus_adv', 0), ('chem_adv', 0), ('bio_adv', 0), ('geo_adv', 0), ('for_base', 0)]\n",
      "[('for_adv', 37), ('geo_base', 32), ('it_base', 31), ('alg_adv', 22), ('soc_base', 22), ('his_base', 22), ('phy_base', 20), ('chem_base', 20), ('bio_base', 20), ('it_adv', 18), ('soc_adv', 17), ('no_adv', 17), ('lit_base', 17), ('geom_adv', 15), ('lit_adv', 15), ('phy_adv', 14), ('no_base', 14), ('rus_adv', 13), ('his_adv', 12), ('for_base', 10), ('chem_adv', 9), ('geo_adv', 8), ('geom_base', 8), ('rus_base', 8), ('alg_base', 7), ('bio_adv', 5)]\n",
      "Top 2 score is 0.881578947368421\n",
      "Mean real num is 5.697368421052632\n",
      "Mean good num is 1.381578947368421\n",
      "[('for_adv', 28), ('geo_base', 25), ('it_base', 22), ('alg_adv', 20), ('no_adv', 17), ('his_base', 16), ('no_base', 14), ('chem_base', 10), ('soc_adv', 9), ('soc_base', 9), ('lit_adv', 8), ('it_adv', 7), ('geom_base', 7), ('bio_base', 6), ('his_adv', 5), ('phy_base', 5), ('geom_adv', 4), ('phy_adv', 4), ('rus_adv', 3), ('alg_base', 3), ('lit_base', 3), ('for_base', 2), ('rus_base', 1), ('chem_adv', 0), ('bio_adv', 0), ('geo_adv', 0)]\n",
      "[('for_adv', 37), ('geo_base', 32), ('it_base', 31), ('alg_adv', 22), ('soc_base', 22), ('his_base', 22), ('phy_base', 20), ('chem_base', 20), ('bio_base', 20), ('it_adv', 18), ('soc_adv', 17), ('no_adv', 17), ('lit_base', 17), ('geom_adv', 15), ('lit_adv', 15), ('phy_adv', 14), ('no_base', 14), ('rus_adv', 13), ('his_adv', 12), ('for_base', 10), ('chem_adv', 9), ('geo_adv', 8), ('geom_base', 8), ('rus_base', 8), ('alg_base', 7), ('bio_adv', 5)]\n",
      "Top 3 score is 0.8947368421052632\n",
      "Mean real num is 5.697368421052632\n",
      "Mean good num is 1.894736842105263\n",
      "[('geo_base', 35), ('for_adv', 34), ('it_base', 27), ('alg_adv', 21), ('his_base', 20), ('no_adv', 17), ('chem_base', 16), ('soc_base', 16), ('no_base', 16), ('bio_base', 14), ('soc_adv', 12), ('lit_adv', 10), ('it_adv', 10), ('geom_adv', 7), ('phy_adv', 7), ('geom_base', 7), ('phy_base', 7), ('his_adv', 6), ('for_base', 6), ('alg_base', 5), ('lit_base', 5), ('rus_adv', 4), ('rus_base', 2), ('chem_adv', 0), ('bio_adv', 0), ('geo_adv', 0)]\n",
      "[('for_adv', 37), ('geo_base', 32), ('it_base', 31), ('alg_adv', 22), ('soc_base', 22), ('his_base', 22), ('phy_base', 20), ('chem_base', 20), ('bio_base', 20), ('it_adv', 18), ('soc_adv', 17), ('no_adv', 17), ('lit_base', 17), ('geom_adv', 15), ('lit_adv', 15), ('phy_adv', 14), ('no_base', 14), ('rus_adv', 13), ('his_adv', 12), ('for_base', 10), ('chem_adv', 9), ('geo_adv', 8), ('geom_base', 8), ('rus_base', 8), ('alg_base', 7), ('bio_adv', 5)]\n",
      "Top 4 score is 0.9342105263157895\n",
      "Mean real num is 5.697368421052632\n",
      "Mean good num is 2.3947368421052633\n",
      "[('geo_base', 44), ('for_adv', 38), ('it_base', 36), ('his_base', 25), ('alg_adv', 23), ('chem_base', 20), ('soc_base', 18), ('no_adv', 17), ('no_base', 17), ('lit_adv', 16), ('soc_adv', 16), ('bio_base', 16), ('it_adv', 13), ('lit_base', 13), ('phy_adv', 10), ('geom_adv', 9), ('his_adv', 9), ('phy_base', 9), ('geom_base', 8), ('for_base', 7), ('rus_adv', 5), ('alg_base', 5), ('rus_base', 3), ('chem_adv', 1), ('bio_adv', 1), ('geo_adv', 1)]\n",
      "[('for_adv', 37), ('geo_base', 32), ('it_base', 31), ('alg_adv', 22), ('soc_base', 22), ('his_base', 22), ('phy_base', 20), ('chem_base', 20), ('bio_base', 20), ('it_adv', 18), ('soc_adv', 17), ('no_adv', 17), ('lit_base', 17), ('geom_adv', 15), ('lit_adv', 15), ('phy_adv', 14), ('no_base', 14), ('rus_adv', 13), ('his_adv', 12), ('for_base', 10), ('chem_adv', 9), ('geo_adv', 8), ('geom_base', 8), ('rus_base', 8), ('alg_base', 7), ('bio_adv', 5)]\n",
      "Top 5 score is 0.9736842105263158\n",
      "Mean real num is 5.697368421052632\n",
      "Mean good num is 2.723684210526316\n"
     ]
    }
   ],
   "source": [
    "#цикл для оценки качества модели\n",
    "probs = []\n",
    "for e in range(1,6):\n",
    "    predictions = [list(zip(predicts, subjs)) for predicts in np.transpose(subj_log_predictions)]\n",
    "    reals = [list(zip(real, subjs)) for real in np.transpose(subj_log_real)]\n",
    "    #print(sorted(real[111], reverse = True))\n",
    "    pred_dist = {}\n",
    "    real_dist = {}\n",
    "    for subj in subjs:\n",
    "        pred_dist[subj]=0\n",
    "        real_dist[subj]=0\n",
    "    good = 0\n",
    "    num = len(reals)\n",
    "    all_real = 0\n",
    "    all_goods = 0\n",
    "    top_num = e\n",
    "    #цикл сравнивающий показатели для каждого пользователя в отдельности\n",
    "    #с предсказанием, которое модель дала для пользователя\n",
    "    for i in range(num):\n",
    "        pred = [preds[1] for preds in sorted(predictions[i], reverse = True)][0:top_num]\n",
    "        real = [real[1] for real in sorted(reals[i], reverse = True) if real[0]==1]\n",
    "        for z in real:\n",
    "            real_dist[z]+=1\n",
    "        sum_real = sum([real_dist[x] for x in real_dist])\n",
    "        #Два варианта создания случайных прогноза: с и без оглядки \n",
    "        #на распределение предметов по выборке\n",
    "        #pred = np.random.choice(subjs, top_num, p = [real_dist[x]/sum_real for x in real_dist])\n",
    "        #pred = np.random.choice(subjs, top_num)\n",
    "        all_real += len(real)\n",
    "        for z in real:\n",
    "            if z in pred:\n",
    "                good = good+1\n",
    "                break\n",
    "        for z in real:\n",
    "            if z in pred:\n",
    "                all_goods +=1\n",
    "        for z in pred:\n",
    "            pred_dist[z]+=1\n",
    "    #Вывод статистики по получившейся модели\n",
    "    print([(x, pred_dist[x]) for x in sorted(pred_dist, key=pred_dist.get, reverse = True)])\n",
    "    print([(x, real_dist[x]) for x in sorted(real_dist, key=real_dist.get, reverse = True)])\n",
    "    print('Top {0} score is {1}'.format(top_num, good/num))\n",
    "    print('Mean real num is {0}'.format(all_real/num))\n",
    "    print('Mean good num is {0}'.format(all_goods/num))\n",
    "    probs.append(good/(num+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gum\n",
      "Dummy score: 0.632\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.6696428571428572\n",
      "Train score: 0.887\n",
      "Test score: 0.645\n",
      "[[36 15]\n",
      " [12 13]]\n",
      "LinearSVC\n",
      "Train score: 0.96\n",
      "Test score: 0.579\n",
      "[[33 17]\n",
      " [15 11]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.791\n",
      "Test score: 0.645\n",
      "[[40 19]\n",
      " [ 8  9]]\n",
      "MultinomialNB\n",
      "AUC score 0.7247023809523809\n",
      "Train score: 0.802\n",
      "Test score: 0.684\n",
      "[[35 11]\n",
      " [13 17]]\n",
      "BernoulliNB\n",
      "AUC score 0.7269345238095238\n",
      "Train score: 0.819\n",
      "Test score: 0.684\n",
      "[[34 10]\n",
      " [14 18]]\n",
      "GaussianNB\n",
      "AUC score 0.6462053571428571\n",
      "Train score: 0.52\n",
      "Test score: 0.395\n",
      "[[ 6  4]\n",
      " [42 24]]\n",
      "\n",
      "\n",
      "it\n",
      "Dummy score: 0.882\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7512437810945274\n",
      "Train score: 0.938\n",
      "Test score: 0.908\n",
      "[[66  6]\n",
      " [ 1  3]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.842\n",
      "[[60  5]\n",
      " [ 7  4]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.87\n",
      "Test score: 0.882\n",
      "[[66  8]\n",
      " [ 1  1]]\n",
      "MultinomialNB\n",
      "AUC score 0.7296849087893864\n",
      "Train score: 0.898\n",
      "Test score: 0.868\n",
      "[[64  7]\n",
      " [ 3  2]]\n",
      "BernoulliNB\n",
      "AUC score 0.7230514096185738\n",
      "Train score: 0.881\n",
      "Test score: 0.868\n",
      "[[63  6]\n",
      " [ 4  3]]\n",
      "GaussianNB\n",
      "AUC score 0.5862354892205639\n",
      "Train score: 0.379\n",
      "Test score: 0.355\n",
      "[[19  1]\n",
      " [48  8]]\n",
      "\n",
      "\n",
      "econ\n",
      "Dummy score: 0.645\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.6220710506424791\n",
      "Train score: 0.825\n",
      "Test score: 0.645\n",
      "[[43 21]\n",
      " [ 6  6]]\n",
      "LinearSVC\n",
      "Train score: 0.932\n",
      "Test score: 0.632\n",
      "[[39 18]\n",
      " [10  9]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.797\n",
      "Test score: 0.632\n",
      "[[45 24]\n",
      " [ 4  3]]\n",
      "MultinomialNB\n",
      "AUC score 0.6409674981103552\n",
      "Train score: 0.802\n",
      "Test score: 0.618\n",
      "[[39 19]\n",
      " [10  8]]\n",
      "BernoulliNB\n",
      "AUC score 0.6318972033257747\n",
      "Train score: 0.785\n",
      "Test score: 0.618\n",
      "[[38 18]\n",
      " [11  9]]\n",
      "GaussianNB\n",
      "AUC score 0.5260770975056689\n",
      "Train score: 0.463\n",
      "Test score: 0.421\n",
      "[[ 8  3]\n",
      " [41 24]]\n",
      "\n",
      "\n",
      "ped\n",
      "Dummy score: 0.921\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.5452380952380953\n",
      "Train score: 0.932\n",
      "Test score: 0.908\n",
      "[[69  6]\n",
      " [ 1  0]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.895\n",
      "[[68  6]\n",
      " [ 2  0]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.932\n",
      "Test score: 0.921\n",
      "[[70  6]\n",
      " [ 0  0]]\n",
      "MultinomialNB\n",
      "AUC score 0.5428571428571429\n",
      "Train score: 0.938\n",
      "Test score: 0.908\n",
      "[[69  6]\n",
      " [ 1  0]]\n",
      "BernoulliNB\n",
      "AUC score 0.5214285714285715\n",
      "Train score: 0.938\n",
      "Test score: 0.908\n",
      "[[69  6]\n",
      " [ 1  0]]\n",
      "GaussianNB\n",
      "AUC score 0.49523809523809526\n",
      "Train score: 0.678\n",
      "Test score: 0.632\n",
      "[[46  4]\n",
      " [24  2]]\n",
      "\n",
      "\n",
      "med\n",
      "Dummy score: 0.921\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.6738095238095239\n",
      "Train score: 0.949\n",
      "Test score: 0.908\n",
      "[[69  6]\n",
      " [ 1  0]]\n",
      "LinearSVC\n",
      "Train score: 1.0\n",
      "Test score: 0.842\n",
      "[[63  5]\n",
      " [ 7  1]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.927\n",
      "Test score: 0.908\n",
      "[[69  6]\n",
      " [ 1  0]]\n",
      "MultinomialNB\n",
      "AUC score 0.5571428571428572\n",
      "Train score: 0.944\n",
      "Test score: 0.921\n",
      "[[69  5]\n",
      " [ 1  1]]\n",
      "BernoulliNB\n",
      "AUC score 0.5404761904761906\n",
      "Train score: 0.932\n",
      "Test score: 0.908\n",
      "[[68  5]\n",
      " [ 2  1]]\n",
      "GaussianNB\n",
      "AUC score 0.35714285714285715\n",
      "Train score: 0.757\n",
      "Test score: 0.658\n",
      "[[50  6]\n",
      " [20  0]]\n",
      "\n",
      "\n",
      "est\n",
      "Dummy score: 0.947\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.7534722222222222\n",
      "Train score: 0.927\n",
      "Test score: 0.934\n",
      "[[71  4]\n",
      " [ 1  0]]\n",
      "LinearSVC\n",
      "Train score: 0.994\n",
      "Test score: 0.908\n",
      "[[67  2]\n",
      " [ 5  2]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.915\n",
      "Test score: 0.947\n",
      "[[72  4]\n",
      " [ 0  0]]\n",
      "MultinomialNB\n",
      "AUC score 0.8263888888888888\n",
      "Train score: 0.944\n",
      "Test score: 0.961\n",
      "[[71  2]\n",
      " [ 1  2]]\n",
      "BernoulliNB\n",
      "AUC score 0.8229166666666666\n",
      "Train score: 0.944\n",
      "Test score: 0.961\n",
      "[[71  2]\n",
      " [ 1  2]]\n",
      "GaussianNB\n",
      "AUC score 0.5138888888888888\n",
      "Train score: 0.723\n",
      "Test score: 0.75\n",
      "[[56  3]\n",
      " [16  1]]\n",
      "\n",
      "\n",
      "ing\n",
      "Dummy score: 0.882\n",
      "Dummy AUC score 0.5\n",
      "Logistic regression\n",
      "AUC score 0.835820895522388\n",
      "Train score: 0.927\n",
      "Test score: 0.868\n",
      "[[61  4]\n",
      " [ 6  5]]\n",
      "LinearSVC\n",
      "Train score: 0.977\n",
      "Test score: 0.789\n",
      "[[54  3]\n",
      " [13  6]]\n",
      "KNeighborsClassifier\n",
      "Train score: 0.842\n",
      "Test score: 0.895\n",
      "[[66  7]\n",
      " [ 1  2]]\n",
      "MultinomialNB\n",
      "AUC score 0.8872305140961857\n",
      "Train score: 0.864\n",
      "Test score: 0.868\n",
      "[[60  3]\n",
      " [ 7  6]]\n",
      "BernoulliNB\n",
      "AUC score 0.8723051409618574\n",
      "Train score: 0.881\n",
      "Test score: 0.842\n",
      "[[57  2]\n",
      " [10  7]]\n",
      "GaussianNB\n",
      "AUC score 0.5041459369817579\n",
      "Train score: 0.367\n",
      "Test score: 0.211\n",
      "[[ 8  1]\n",
      " [59  8]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adm_log_predictions = []\n",
    "adm_log_real = []\n",
    "#загружаем необходимые для анализа данных пакеты из библиотеки sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in adm_short:\n",
    "    curr_subj = [subj for subj in subjs if subj!=i]\n",
    "    X_labeles = list(olymps_full)+list(curr_subj)+list(subjects_eng)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(grades_df[X_labeles],\n",
    "                                                        grades_df[i], random_state = 42, test_size = 0.3)\n",
    "    log_reg = LogisticRegression(penalty='l1')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    svc_reg = LinearSVC()\n",
    "    svc_reg.fit(X_train, y_train)\n",
    "    multy = MultinomialNB()\n",
    "    multy.fit(X_train, y_train)\n",
    "    ber = BernoulliNB()\n",
    "    gauss = GaussianNB()\n",
    "    gauss.fit(X_train, y_train)\n",
    "    ber.fit(X_train, y_train)\n",
    "    knn = KNeighborsClassifier(9)\n",
    "    knn.fit(X_train, y_train)\n",
    "    dummy = DummyClassifier('most_frequent')\n",
    "    dummy.fit(X_train, y_train)\n",
    "    print(i+'\\nDummy score: {0}'.format(round(dummy.score(X_test, y_test),3)))\n",
    "    print('Dummy AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in dummy.predict_proba(X_test)])))\n",
    "    print('Logistic regression')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in log_reg.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(log_reg.score(X_train, y_train),3), round(log_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(log_reg.predict(X_test), y_test))\n",
    "    print('LinearSVC')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(svc_reg.score(X_train, y_train),3), round(svc_reg.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(svc_reg.predict(X_test), y_test))\n",
    "    print('KNeighborsClassifier')\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(knn.score(X_train, y_train),3), round(knn.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(knn.predict(X_test), y_test))\n",
    "    print('MultinomialNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in multy.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(multy.score(X_train, y_train),3), round(multy.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(multy.predict(X_test), y_test))\n",
    "    print('BernoulliNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in ber.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(ber.score(X_train, y_train),3), round(ber.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(ber.predict(X_test), y_test))\n",
    "    print('GaussianNB')\n",
    "    print('AUC score {0}'.format(roc_auc_score(y_test, [a[1] for a in gauss.predict_proba(X_test)])))\n",
    "    print('Train score: {0}\\nTest score: {1}'.format(round(gauss.score(X_train, y_train),3), \n",
    "                                                     round(gauss.score(X_test, y_test),3)))\n",
    "    print(confusion_matrix(gauss.predict(X_test), y_test))\n",
    "    print('\\n')\n",
    "    \n",
    "    adm_log_predictions.append([a[1] for a in log_reg.predict_proba(X_test)])\n",
    "    adm_log_real.append(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gum', 36), ('econ', 15), ('ing', 15), ('it', 5), ('ped', 3), ('med', 2), ('est', 0)]\n",
      "[('gum', 28), ('econ', 27), ('it', 9), ('ing', 9), ('ped', 6), ('med', 6), ('est', 4)]\n",
      "Top 1 score is 0.42857142857142855\n",
      "Mean real num is 1.1710526315789473\n",
      "Mean good num is 0.4342105263157895\n",
      "[('gum', 52), ('econ', 43), ('ing', 24), ('it', 11), ('med', 10), ('ped', 7), ('est', 5)]\n",
      "[('gum', 28), ('econ', 27), ('it', 9), ('ing', 9), ('ped', 6), ('med', 6), ('est', 4)]\n",
      "Top 2 score is 0.6623376623376623\n",
      "Mean real num is 1.1710526315789473\n",
      "Mean good num is 0.7368421052631579\n",
      "[('gum', 61), ('econ', 53), ('ing', 37), ('it', 24), ('med', 24), ('ped', 17), ('est', 12)]\n",
      "[('gum', 28), ('econ', 27), ('it', 9), ('ing', 9), ('ped', 6), ('med', 6), ('est', 4)]\n",
      "Top 3 score is 0.7532467532467533\n",
      "Mean real num is 1.1710526315789473\n",
      "Mean good num is 0.868421052631579\n",
      "[('gum', 64), ('econ', 62), ('ing', 52), ('it', 44), ('ped', 32), ('med', 30), ('est', 20)]\n",
      "[('gum', 28), ('econ', 27), ('it', 9), ('ing', 9), ('ped', 6), ('med', 6), ('est', 4)]\n",
      "Top 4 score is 0.8701298701298701\n",
      "Mean real num is 1.1710526315789473\n",
      "Mean good num is 1.0\n"
     ]
    }
   ],
   "source": [
    "#цикл для оценки качества модели\n",
    "probs = []\n",
    "for e in range(1,5):\n",
    "    predictions = [list(zip(predicts, adm_short)) for predicts in np.transpose(adm_log_predictions)]\n",
    "    reals = [list(zip(real, adm_short)) for real in np.transpose(adm_log_real)]\n",
    "    #print(sorted(real[111], reverse = True))\n",
    "    pred_dist = {}\n",
    "    real_dist = {}\n",
    "    for adm in adm_short:\n",
    "        pred_dist[adm]=0\n",
    "        real_dist[adm]=0\n",
    "    good = 0\n",
    "    num = len(reals)\n",
    "    all_real = 0\n",
    "    all_goods = 0\n",
    "    top_num = e\n",
    "    #цикл сравнивающий показатели для каждого пользователя в отдельности\n",
    "    #с предсказанием, которое модель дала для пользователя\n",
    "    for i in range(num):\n",
    "        pred = [preds[1] for preds in sorted(predictions[i], reverse = True)][0:top_num]\n",
    "        real = [real[1] for real in sorted(reals[i], reverse = True) if real[0]==1]\n",
    "        for z in real:\n",
    "            real_dist[z]+=1\n",
    "        sum_real = sum([real_dist[x] for x in real_dist])\n",
    "        #Два варианта создания случайных прогноза: с и без оглядки \n",
    "        #на распределение предметов по выборке\n",
    "        #pred = np.random.choice(adm_short, top_num, p = [real_dist[x]/sum_real for x in real_dist])\n",
    "        #pred = np.random.choice(subjs, top_num)\n",
    "        all_real += len(real)\n",
    "        for z in real:\n",
    "            if z in pred:\n",
    "                good = good+1\n",
    "                break\n",
    "        for z in real:\n",
    "            if z in pred:\n",
    "                all_goods +=1\n",
    "        for z in pred:\n",
    "            pred_dist[z]+=1\n",
    "    #Вывод статистики по получившейся модели\n",
    "    print([(x, pred_dist[x]) for x in sorted(pred_dist, key=pred_dist.get, reverse = True)])\n",
    "    print([(x, real_dist[x]) for x in sorted(real_dist, key=real_dist.get, reverse = True)])\n",
    "    print('Top {0} score is {1}'.format(top_num, good/(num+1)))\n",
    "    print('Mean real num is {0}'.format(all_real/num))\n",
    "    print('Mean good num is {0}'.format(all_goods/num))\n",
    "    probs.append(good/(num+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56450222229904634, 0.80134193354510952)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#метод для оценки доверительного интервала точности случайной модели\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import math\n",
    " \n",
    "n, min_max, mean, var, skew, kurt = stats.describe(probs)\n",
    "std=math.sqrt(var)\n",
    "\n",
    "R = stats.norm.interval(0.99,loc=mean,scale=std)\n",
    "R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('geo_base', 46), ('for_adv', 43), ('it_base', 34), ('his_base', 26), ('chem_base', 17), ('bio_base', 17), ('alg_adv', 16), ('soc_base', 15), ('lit_adv', 14), ('soc_adv', 14), ('lit_base', 13), ('no_adv', 9), ('it_adv', 7), ('phy_base', 7), ('for_base', 6), ('geom_adv', 4), ('phy_adv', 4), ('no_base', 4), ('his_adv', 3), ('alg_base', 2), ('geom_base', 2), ('rus_adv', 1), ('chem_adv', 0), ('bio_adv', 0), ('geo_adv', 0), ('rus_base', 0)]\n",
      "[('for_adv', 37), ('geo_base', 32), ('it_base', 31), ('alg_adv', 22), ('soc_base', 22), ('his_base', 22), ('phy_base', 20), ('chem_base', 20), ('bio_base', 20), ('it_adv', 18), ('soc_adv', 17), ('no_adv', 17), ('lit_base', 17), ('geom_adv', 15), ('lit_adv', 15), ('phy_adv', 14), ('no_base', 14), ('rus_adv', 13), ('his_adv', 12), ('for_base', 10), ('chem_adv', 9), ('geo_adv', 8), ('geom_base', 8), ('rus_base', 8), ('alg_base', 7), ('bio_adv', 5)]\n",
      "Top 4 score is 0.8571428571428571\n",
      "Mean real num is 5.697368421052632\n",
      "Mean good num is 1.5263157894736843\n"
     ]
    }
   ],
   "source": [
    "predictions = [list(zip(predicts, subjs)) for predicts in np.transpose(subj_log_predictions)]\n",
    "reals = [list(zip(real, subjs)) for real in np.transpose(subj_log_real)]\n",
    "#print(sorted(real[111], reverse = True))\n",
    "pred_dist = {}\n",
    "real_dist = {}\n",
    "for subj in subjs:\n",
    "    pred_dist[subj]=0\n",
    "    real_dist[subj]=0\n",
    "good = 0\n",
    "num = len(reals)\n",
    "all_real = 0\n",
    "all_goods = 0\n",
    "top_num = 4\n",
    "for i in range(num):\n",
    "    pred = [preds[1] for preds in sorted(predictions[i], reverse = True)][0:top_num]\n",
    "    real = [real[1] for real in sorted(reals[i], reverse = True) if real[0]==1]\n",
    "    for z in real:\n",
    "        real_dist[z]+=1\n",
    "    sum_real = sum([real_dist[x] for x in real_dist])\n",
    "    #pred = np.random.choice(subjs, top_num, p = [real_dist[x]/sum_real for x in real_dist])\n",
    "    #pred = np.random.choice(subjs, top_num)\n",
    "    all_real += len(real)\n",
    "    for z in real:\n",
    "        if z in pred:\n",
    "            good = good+1\n",
    "            break\n",
    "    for z in real:\n",
    "        if z in pred:\n",
    "            all_goods +=1\n",
    "    for z in pred:\n",
    "        pred_dist[z]+=1\n",
    "print([(x, pred_dist[x]) for x in sorted(pred_dist, key=pred_dist.get, reverse = True)])\n",
    "print([(x, real_dist[x]) for x in sorted(real_dist, key=real_dist.get, reverse = True)])\n",
    "print('Top {0} score is {1}'.format(top_num, good/(num+1)))\n",
    "print('Mean real num is {0}'.format(all_real/num))\n",
    "print('Mean good num is {0}'.format(all_goods/num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#создание и сохранение массива данных показателей модели Лассо\n",
    "lasso_df = pd.DataFrame(columns = adm_short)\n",
    "for lasso in range(len(lasso_save)):\n",
    "    lasso_dict = {}\n",
    "    for i in lasso_save[lasso]:\n",
    "        lasso_dict[i[0]] = i[1]\n",
    "    lasso_df = lasso_df.append(pd.Series(lasso_dict, name = subjs[lasso]))\n",
    "lasso_df.to_csv('Lasso_params.csv', sep=';', na_rep='0', decimal =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso_df.to_csv('Lasso_params.csv', sep=';', na_rep='0', decimal =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
